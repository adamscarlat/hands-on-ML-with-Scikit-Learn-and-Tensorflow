{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import grpc\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "* Run the docker-compose file to launch TF serving\n",
    "* Train the MNIST model (cell below) and makes sure it's saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 1s 658us/step - loss: 0.6820 - accuracy: 0.8290 - val_loss: 0.3691 - val_accuracy: 0.9010\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 1s 594us/step - loss: 0.3510 - accuracy: 0.9016 - val_loss: 0.3004 - val_accuracy: 0.9152\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 558us/step - loss: 0.3022 - accuracy: 0.9145 - val_loss: 0.2655 - val_accuracy: 0.9264\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 590us/step - loss: 0.2726 - accuracy: 0.9228 - val_loss: 0.2437 - val_accuracy: 0.9326\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 591us/step - loss: 0.2499 - accuracy: 0.9292 - val_loss: 0.2251 - val_accuracy: 0.9388\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 602us/step - loss: 0.2316 - accuracy: 0.9347 - val_loss: 0.2108 - val_accuracy: 0.9410\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 1s 570us/step - loss: 0.2161 - accuracy: 0.9391 - val_loss: 0.1968 - val_accuracy: 0.9464\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 1s 570us/step - loss: 0.2026 - accuracy: 0.9426 - val_loss: 0.1884 - val_accuracy: 0.9494\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 1s 571us/step - loss: 0.1907 - accuracy: 0.9463 - val_loss: 0.1777 - val_accuracy: 0.9518\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 566us/step - loss: 0.1803 - accuracy: 0.9493 - val_loss: 0.1684 - val_accuracy: 0.9526\n",
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_mnist_model/0002/assets\n"
     ]
    }
   ],
   "source": [
    "# Training a model on MNIST. We'll use it as an example model for this chapter\n",
    "\n",
    "mnist = tf.keras.datasets.mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# extra code â€“ build & train an MNIST model (also handles image preprocessing)\n",
    "tf.random.set_seed(42)\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=[28, 28], dtype=tf.uint8),\n",
    "    tf.keras.layers.Rescaling(scale=1 / 255),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "\n",
    "model_name = \"my_mnist_model\"\n",
    "model_version = \"0002\"\n",
    "model_path = Path(model_name) / model_version\n",
    "model.save(model_path, save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals:      [7 2 1 0 4 1 4 9 5 9]\n",
      "Predictions:  [7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# Querying TF serving through the REST API\n",
    "\n",
    "# n example instances for inference\n",
    "n = 10\n",
    "X_new = X_test[:n]\n",
    "\n",
    "# Serving_default points to the model we want to use.\n",
    "# We need to convert numpy array to python list and serialize to json\n",
    "request_json = json.dumps({\n",
    "  \"signature_name\": \"serving_default\",\n",
    "  \"instances\": X_new.tolist()\n",
    "})\n",
    "\n",
    "# Making the request\n",
    "server_url = \"http://localhost:8501/v1/models/my_mnist_model:predict\"\n",
    "response = requests.post(server_url, data=request_json)\n",
    "response.raise_for_status()\n",
    "response = response.json()\n",
    "\n",
    "# Parsing the response\n",
    "y_proba = np.array(response[\"predictions\"])\n",
    "preds = np.argmax(y_proba, axis=1)\n",
    "print (\"Actuals:     \", y_test[:n])\n",
    "print (\"Predictions: \", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuals:      [7 2 1 0 4 1 4 9 5 9]\n",
      "Predictions:  [7 2 1 0 4 1 4 9 6 9]\n"
     ]
    }
   ],
   "source": [
    "# Querying TF serving through the gRPC API\n",
    "\n",
    "# Create and populate a protocol buffer \n",
    "request = PredictRequest()\n",
    "request.model_spec.name = model_name\n",
    "request.model_spec.signature_name = \"serving_default\"\n",
    "\n",
    "# Input layer of the model: flatten_input\n",
    "input_name = model.input_names[0]\n",
    "\n",
    "# Populate the input\n",
    "request.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))\n",
    "\n",
    "# Make the request\n",
    "channel = grpc.insecure_channel(\"localhost:8500\")\n",
    "predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "response = predict_service.Predict(request, timeout=10.0)\n",
    "\n",
    "# Parse response\n",
    "\n",
    "# Output layer name of the model: dense_1\n",
    "output_name = model.output_names[0]\n",
    "outputs_proto = response.outputs[output_name]\n",
    "y_proba = tf.make_ndarray(outputs_proto)\n",
    "\n",
    "preds = np.argmax(y_proba, axis=1)\n",
    "print (\"Actuals:     \", y_test[:n])\n",
    "print (\"Predictions: \", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
