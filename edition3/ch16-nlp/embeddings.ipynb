{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import shutil\n",
    "import string\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). \n",
    "\n",
    "Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
    "\n",
    "### The IMDB Dataset\n",
    "\n",
    "We'll use the IMDB dataset to train a sentiment classifier model (classifies good / bad per review) and in the process learn the \n",
    "embeddings from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imdbEr.txt', 'test', 'imdb.vocab', 'README', 'train']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the data\n",
    "\n",
    "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url, untar=True, cache_dir='.', cache_subdir='')\n",
    "\n",
    "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "os.listdir(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing not needed data (unsupervised)\n",
    "\n",
    "remove_dir = os.path.join(\"datasets/aclImdb/train\", \"unsup\")\n",
    "shutil.rmtree(remove_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Creating train / valid datasets from the data\n",
    "\n",
    "batch_size = 1024\n",
    "seed = 123\n",
    "\n",
    "train_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "  \"datasets/aclImdb/train\", batch_size=batch_size, validation_split=0.2,\n",
    "  subset=\"training\", seed=seed\n",
    ")\n",
    "\n",
    "valid_ds = tf.keras.utils.text_dataset_from_directory(\n",
    "  \"datasets/aclImdb/train\", batch_size=batch_size, validation_split=0.2,\n",
    "  subset=\"validation\", seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 b\"Wow. Some movies just leave me speechless. This was undeniably one of those movies. When I left the theatre, not a single word came to my mouth. All I had was an incredible urge to slam my head against the theatre wall to help me forget about the last hour and a half. Unfortunately, it didn't work. Honestly, this movie has nothing to recommend. The humor was at the first grade level, at best, the acting was overly silly, and the plot was astronomically far-fetched. I hearby pledge never to see an other movie starring Chris Kattan or any other cast-member of SNL.\"\n",
      "1 b'If any show in the last ten years deserves a 10, it is this rare gem. It allows us to escape back to a time when things were simpler and more fun. Filled with heart and laughs, this show keeps you laughing through the three decades of difference. The furniture was ugly, the clothes were colorful, and the even the drugs were tolerable. The hair was feathered, the music was accompanied by roller-skates, and in the words of Merle Haggard, \"a joint was a bad place to be\". Take a trip back to the greatest time in American history. Fall in love with characters and the feel good essence of the small town where people were nicer to each other. This classic is on television as much as \"Full House\". Don\\'t miss it, and always remember to \"Shake your groove thing!!!\"'\n",
      "1 b'Clearly an hilarious movie.<br /><br />It angers me to see the poor ratings given to this piece of comic genius<br /><br />Please look at this for what it is, a funny, ridiculous enjoyable film. Laugh for christ sake!<br /><br />'\n",
      "0 b\"Distasteful, cliched thriller has young couple doing cross-country research on America's most infamous murder sites, becoming road partners with a dim-witted young woman and her snarling boyfriend--who is an actual psycho. Arty and alienating, the film's tone alternates between pouty pseudo-irony and silly flamboyance. Handsomely-made perhaps, but ultimately laughable. Brad Pitt's performance as the low-rent killer is godawful. * from ****\"\n",
      "1 b\"Scott is right. The best 2 person sword duel ever put on film is in the middle of this movie. The sword fights with multiple fighters are not the best although quite good. However, the fight in the middle is the best even compared to Japanese samurai movies. Chinese swordplay scenes in my opinion have never surpassed the Japanese in terms of entertainment value. Especially in scenes where one guy must battle a group of enemies, Japanese movies excel, example being the Lone Wolf and Cub series. Even though duels in Japanese cinema last only seconds or a minute at the most, the sheer intensity of those moments made them better. But, this is one example where Chinese swordplay surpasses the Japanese. The scene in the middle of this film was a five minute long fight with the most amazing choreography ever. The other fights in this movie are good too but even if they sucked this movie would get a 7 for that one scene. If you haven't seen it, you have to. John Woo is the man.\"\n"
     ]
    }
   ],
   "source": [
    "# Reviewing the data\n",
    "\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "  for i in range(5):\n",
    "    print (label_batch[i].numpy(), text_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding I/O related optimizations\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = valid_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.04298798  0.03699524  0.00390378  0.0481695  -0.01569118]\n",
      " [-0.03501638  0.00071711  0.03650563 -0.01208202  0.04265844]\n",
      " [-0.02323675 -0.04148346  0.00130652 -0.03028941  0.03238395]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "(2, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# Exploring the embedding layer\n",
    "\n",
    "# Keras embedding layer maps integers (word ids) to their corresponding dense vectors.\n",
    "# For example, this embedding layer embeds 1,000 word vocabulary into 5 dimensions (per word)\n",
    "embedding_layer = tf.keras.layers.Embedding(1000, 5)\n",
    "\n",
    "# The embedding layer starts off with random weights. When we pass a list of integers to it (representing word ids), \n",
    "# we get back their corresponding embedded vectors.\n",
    "result = embedding_layer(tf.constant([1,2,3]))\n",
    "print (result.numpy())\n",
    "\n",
    "print (\"-\" * 100)\n",
    "\n",
    "# Since we'll be working in batches, we'll send to this layer a list of integers (representing ids from words\n",
    "# of multiple sentences). The result will be a tensor of shape (batch_size, seq_length, embedding_dim)\n",
    "result = embedding_layer(tf.constant([[1,2,3], [4,5,6]]))\n",
    "# 2 sentences, each with 3 words, each word mapped to 5 dimensions\n",
    "print (result.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing\n",
    "\n",
    "# Create a custom standardization function to strip HTML break tags '<br />'.\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "  \n",
    "  return tf.strings.regex_replace(stripped_html, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "vocab_size = 1000\n",
    "sequence_length = 100\n",
    "\n",
    "# Normalize, split and map strings to integers. This will keep the most frequent 1000 words\n",
    "# and set all sequences to length of 100 (using padding and cropping).\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "  standardize=custom_standardization,\n",
    "  max_tokens=vocab_size,\n",
    "  output_mode='int',\n",
    "  output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "# Get the text (no labels) to vectorize (only adapting, vectorization happens in the network)\n",
    "text_ds = train_ds.map(lambda x,y : x)\n",
    "vectorize_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.5099INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 26s 1s/step - loss: 0.6927 - accuracy: 0.5099 - val_loss: 0.6920 - val_accuracy: 0.5268\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6884 - accuracy: 0.5606INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 19s 978ms/step - loss: 0.6884 - accuracy: 0.5606 - val_loss: 0.6819 - val_accuracy: 0.5750\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.6214INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 19s 989ms/step - loss: 0.6550 - accuracy: 0.6214 - val_loss: 0.6303 - val_accuracy: 0.6614\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.7258INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 19s 1s/step - loss: 0.5552 - accuracy: 0.7258 - val_loss: 0.5052 - val_accuracy: 0.7606\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.7717INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 20s 1s/step - loss: 0.4867 - accuracy: 0.7717 - val_loss: 0.4644 - val_accuracy: 0.7836\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7952INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 20s 1s/step - loss: 0.4509 - accuracy: 0.7952 - val_loss: 0.4544 - val_accuracy: 0.7926\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 5s 224ms/step - loss: 0.4329 - accuracy: 0.8054 - val_loss: 0.4522 - val_accuracy: 0.7908\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8084INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: embedding_imdb/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 20s 1s/step - loss: 0.4278 - accuracy: 0.8084 - val_loss: 0.4517 - val_accuracy: 0.7944\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 5s 244ms/step - loss: 0.4189 - accuracy: 0.8154 - val_loss: 0.4522 - val_accuracy: 0.7928\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 5s 239ms/step - loss: 0.4137 - accuracy: 0.8167 - val_loss: 0.4522 - val_accuracy: 0.7936\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "\n",
    "embed_size = 16\n",
    "model = tf.keras.Sequential([\n",
    "  vectorize_layer,\n",
    "  tf.keras.layers.Embedding(vocab_size, embed_size, mask_zero=True),\n",
    "  tf.keras.layers.GRU(32),\n",
    "  tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "# Using tensorboard for visualizations\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "# Compile and fit\n",
    "model_ckpt = tf.keras.callbacks.ModelCheckpoint(\"embedding_imdb\", monitor=\"val_accuracy\", save_best_only=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(train_ds, validation_data=valid_ds, epochs=10, callbacks=[ model_ckpt , tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with the trained embeddings\n",
    "\n",
    "# The embeddings are the weights of the embedding layer. The weight matrix is of shape (vocab_size, embedding_dimension) which\n",
    "# makes sense as each word in our vocab has an embedded vector.\n",
    "weights = model.get_layer('embedding_4').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "\n",
    "# Saving the embedding to disk so that we can upload them to embedding projector.\n",
    "out_v = io.open(\"vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
    "out_m = io.open(\"metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  # skipping padding\n",
    "  if index == 0:\n",
    "    continue\n",
    "  \n",
    "  # writing the dense vector to TSV file\n",
    "  vec = weights[index]\n",
    "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()\n",
    "\n",
    "# Now go to Embedding Projector and upload the files to visualize the embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
