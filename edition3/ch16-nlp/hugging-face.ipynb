{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998143315315247}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a trained sentiment-analysis classifier\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\") # many other tasks are available\n",
    "result = classifier(\"The actors were very convincing\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9240571856498718}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example for bias\n",
    "\n",
    "classifier([\"I am Democrat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another example - generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 656/656 [00:00<00:00, 1.07MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 479M/479M [00:07<00:00, 62.4MB/s] \n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFOpenAIGPTLMHeadModel: ['h.7.attn.bias', 'h.0.attn.bias', 'h.4.attn.bias', 'h.5.attn.bias', 'h.10.attn.bias', 'h.8.attn.bias', 'h.9.attn.bias', 'h.6.attn.bias', 'h.11.attn.bias', 'h.3.attn.bias', 'h.2.attn.bias', 'h.1.attn.bias']\n",
      "- This IS expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFOpenAIGPTLMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFOpenAIGPTLMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Get the open-ai gpt, pre-trained model\n",
    "\n",
    "from transformers import TFOpenAIGPTLMHeadModel\n",
    "\n",
    "model = TFOpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 816k/816k [00:00<00:00, 8.36MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 458k/458k [00:00<00:00, 20.6MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.27M/1.27M [00:00<00:00, 21.1MB/s]\n",
      "ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n"
     ]
    }
   ],
   "source": [
    "# Get the model's tokenizer\n",
    "\n",
    "from transformers import OpenAIGPTTokenizer\n",
    "\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained(\"openai-gpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [3570, 1473], 'attention_mask': [1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print (tokenizer(\"hello everyone\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187]], dtype=int32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text = \"This royal throne of kings, this sceptred isle\"\n",
    "encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"tf\")\n",
    "encoded_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 50), dtype=int32, numpy=\n",
       "array([[  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   240,   668,   781,   481,  3032,   240,   488,   781,\n",
       "          487,  1072,   507,   715,   513,   756,   239,   487,   603,\n",
       "          485,   513,   240,   244,   547,  2021,   240,   812,   512,\n",
       "          851,   481,  2817,  3859,   481,  1119,   498,   246,   618,\n",
       "          257,   488,   674,   812,   512],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   267,   520,   636,   580,   481, 22685,   239, 40477,\n",
       "          244,   921,   481,  1813,   597,   239,   244, 40477,   491,\n",
       "          929,   240, 20991,   866,   481,  1002,  5740,   485,   513,\n",
       "         1173,   240,   674,   481,  2216,  1351,   485,  2071,   239,\n",
       "          998,   507,  2337,  1879,   240],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   509,   246,  3458,  1101, 15834,   240,   488,   487,\n",
       "         1313,   507,   481,  1436,   535,   770,   485,  4244,   246,\n",
       "         4483,   984,   626,   595,  1189,   488,   485,  2071,   240,\n",
       "         2335,  3491,  5187,   240,   522,   921,  1250,   500,   246,\n",
       "         6797,   984,   636,   925,  1033],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,   498,   481,   869, 11090,   742,   557,  1163,   562,\n",
       "          481,  3329,   270,   597,  2335,   604,   754,  5394,   989,\n",
       "         2707,   481,  4947,  1594,   239,   702, 16025,   240,   557,\n",
       "          600,   604,   848, 32735,   240,   702,   754,  4353,  2757,\n",
       "          240,   600,   604,  4353,   754],\n",
       "       [  616,  5751,  6404,   498,  9606,   240,   616, 26271,  7428,\n",
       "        16187,  2821,  3779,   485,  1082,   239,   568,   507,  2821,\n",
       "          580,   622,  6588,   485, 32871,   599,   544, 26874,  1437,\n",
       "          239,   256, 40477,  1203,  1709,   498,   481,  4483,  1978,\n",
       "          617,   481, 13582,   488,  1351,   485,  6006,   785,   485,\n",
       "          481,   618,   535,   770,   240]], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 5 sentences, each 40 tokens using the prompt_text\n",
    "\n",
    "num_sequences = 5\n",
    "length = 40\n",
    "\n",
    "generated_sequences = model.generate(\n",
    "    input_ids=encoded_prompt,\n",
    "    do_sample=True,\n",
    "    max_length=length + len(encoded_prompt[0]),\n",
    "    temperature=1.0,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.0,\n",
    "    num_return_sequences=num_sequences,\n",
    ")\n",
    "\n",
    "generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this royal throne of kings, this sceptred isle, just before the battle, and before he put it over her head. he said to her, \" my child, will you let the metal accept the love of a king? and then will you\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle! she would be the regent. \n",
      " \" take the ring now. \" \n",
      " at first, melaina thought the voice belonged to her mother, then the figure began to speak. though it sounded human,\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle was a godless entity, and he held it the god's right to command a council which did not open and to speak, nor indeed discuss, or take part in a discussion which would make anything\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle of the angaraks as home for the forest ; now nor have their cursed people entered the inner land. by extension, as they have come hither, by their marked path, they have marked their\n",
      "--------------------------------------------------------------------------------\n",
      "this royal throne of kings, this sceptred isle shall rise to place. but it shall be our responsibility to safeguard what is rightfully ours.'\n",
      " three others of the council rose from the benches and began to gather around to the king's right,\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Decode the sentences\n",
    "\n",
    "for sequence in generated_sequences:\n",
    "    text = tokenizer.decode(sequence, clean_up_tokenization_spaces=True)\n",
    "    print(text)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
