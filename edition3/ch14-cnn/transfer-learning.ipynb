{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from sklearn.datasets import load_sample_images \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning\n",
    "\n",
    "Using CNNs models that are built into Keras.\n",
    "\n",
    "First we see how to load a model (ResNet50) and use it to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 518ms/step\n",
      "(2, 1000)\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 1us/step\n",
      "Image #0\n",
      "  n03877845 - palace       54.69%\n",
      "  n03781244 - monastery    24.71%\n",
      "  n02825657 - bell_cote    18.55%\n",
      "Image #1\n",
      "  n04522168 - vase         32.67%\n",
      "  n11939491 - daisy        17.82%\n",
      "  n03530642 - honeycomb    12.04%\n"
     ]
    }
   ],
   "source": [
    "# Getting a ResNet 50 model that was trained on the imagenet dataset\n",
    "model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n",
    "\n",
    "# This model expects 224x224 images. We'll resize the images\n",
    "images = load_sample_images()[\"images\"]\n",
    "images_resized = tf.keras.layers.Resizing(height=224, width=224, crop_to_aspect_ratio=True)(images)\n",
    "\n",
    "# Built-in models have a preprocess_input function that does additional needed preprocessing\n",
    "inputs = tf.keras.applications.resnet50.preprocess_input(images_resized)\n",
    "\n",
    "# Making predictions\n",
    "Y_proba = model.predict(inputs)\n",
    "\n",
    "# This model is trained to classify 1000 types of objects in images. Therefore, the output dims is (input_size, 1000)\n",
    "print (Y_proba.shape)\n",
    "\n",
    "# The model comes with a \"decode prediction\" function that puts a label to the result\n",
    "top_K = tf.keras.applications.resnet50.decode_predictions(Y_proba, top=3)\n",
    "for image_index in range(len(images)):\n",
    "  print (f\"Image #{image_index}\")\n",
    "  for class_id, name, y_proba in top_K[image_index]:\n",
    "    print (f\"  {class_id} - {name:12s} {y_proba:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception as a base model to classify flower types\n",
    "\n",
    "Now let's use Xception to classify types of flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the flowers dataset. Use a train/valid/test split\n",
    "dataset, info = tfds.load(\"tf_flowers\", \n",
    "                          split=[\"train[:10%]\", \"train[10%:25%]\", \"train[25%:]\"],\n",
    "                          as_supervised=True, \n",
    "                          with_info=True)\n",
    "\n",
    "# get the dataset info\n",
    "dataset_size = info.splits[\"train\"].num_examples\n",
    "class_names = info.features[\"label\"].names\n",
    "n_classes = info.features[\"label\"].num_classes\n",
    "\n",
    "test_set_raw, valid_set_raw, train_set_raw = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Resizing and using the Xception built-in preprocessing as a single Keras preprocessing model\n",
    "preprocess = tf.keras.Sequential([\n",
    "  tf.keras.layers.Resizing(height=224, width=224, crop_to_aspect_ratio=True),\n",
    "  tf.keras.layers.Lambda(tf.keras.applications.xception.preprocess_input)\n",
    "])\n",
    "train_set = train_set_raw.map(lambda X,y: (preprocess(X), y))\n",
    "\n",
    "# Shuffle and batch the training set\n",
    "train_set = train_set.shuffle(1000, seed=42).batch(batch_size).prefetch(1)\n",
    "\n",
    "# Preprocess for validation and test sets\n",
    "valid_set = valid_set_raw.map(lambda X,y: (preprocess(X), y))\n",
    "test_set = test_set_raw.map(lambda X,y: (preprocess(X), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding augmentation \n",
    "\n",
    "# During training, it will randomly augment images using this pipeline\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=42),\n",
    "  tf.keras.layers.RandomRotation(factor=0.5, seed=42),\n",
    "  tf.keras.layers.RandomContrast(factor=0.5, seed=42),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    }
   ],
   "source": [
    "# Loading the Xception model\n",
    "\n",
    "# We set include_top=False so that it excludes the global avg pooling and dense output layer.\n",
    "# We'll add our own output softmax layer for the flowers labels\n",
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Adding our own \"top\" layers\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Freezing the weights of the pretrained layers so that we don't corrupt them during training\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting - USE GPU! very slow\n",
    "\n",
    "# We start by doing 3 epochs on the new top with everything below it frozen\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting more layers - USE GPU! very slow\n",
    "\n",
    "# Now that we calibrated the top, we can unfreeze more layers below for training. The first calibration ensures \n",
    "# that the large gradients don't corrupt the well trained layer weights\n",
    "\n",
    "for layer in base_model.layers[56:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "# Need to re-compile\n",
    "# Notice that we decreased the learning rate also to not corrupt the unfrozen, well trained layers\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Training for longer\n",
    "history = model.fit(train_set, validation_data=valid_set, epochs=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Localization\n",
    "\n",
    "Doing transfer learning on the Xception model to output 4 regression values that will be used for a bounding box around an object.\n",
    "\n",
    "**This is just for demonstration. The data does not have bounding boxes that the model can learn from**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.xception.Xception(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "avg = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "# Output the class label (using the 1000 labels the model has)\n",
    "class_output = tf.keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
    "\n",
    "# Output the 4 location values (regression)\n",
    "loc_output = tf.keras.layers.Dense(4)(avg)\n",
    "\n",
    "# The model now has two output types (class probability and location regression values)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=[class_output, loc_output])\n",
    "\n",
    "model.compile(loss=[\"sparse_categorical_crossentropy\", \"mse\"], \n",
    "              loss_weights=[0.8, 0.2], optimizer=optimizer, metrics=[\"accuracy\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
