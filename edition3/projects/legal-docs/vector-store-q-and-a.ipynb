{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import tensorflow_hub as hub\n",
    "from pprint import pprint\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_outcome</th>\n",
       "      <th>case_title</th>\n",
       "      <th>case_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Case1</td>\n",
       "      <td>cited</td>\n",
       "      <td>Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Case2</td>\n",
       "      <td>cited</td>\n",
       "      <td>Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Case3</td>\n",
       "      <td>cited</td>\n",
       "      <td>Colgate Palmolive Co v Cussons Pty Ltd (1993) ...</td>\n",
       "      <td>Ordinarily that discretion will be exercised s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case4</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dais Studio Pty Ltd v Bullett Creative Pty Ltd...</td>\n",
       "      <td>The general principles governing the exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Case5</td>\n",
       "      <td>cited</td>\n",
       "      <td>Dr Martens Australia Pty Ltd v Figgins Holding...</td>\n",
       "      <td>The preceding general principles inform the ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  case_id case_outcome                                         case_title  \\\n",
       "0   Case1        cited  Alpine Hardwood (Aust) Pty Ltd v Hardys Pty Lt...   \n",
       "1   Case2        cited  Black v Lipovac [1998] FCA 699 ; (1998) 217 AL...   \n",
       "2   Case3        cited  Colgate Palmolive Co v Cussons Pty Ltd (1993) ...   \n",
       "3   Case4        cited  Dais Studio Pty Ltd v Bullett Creative Pty Ltd...   \n",
       "4   Case5        cited  Dr Martens Australia Pty Ltd v Figgins Holding...   \n",
       "\n",
       "                                           case_text  \n",
       "0  Ordinarily that discretion will be exercised s...  \n",
       "1  The general principles governing the exercise ...  \n",
       "2  Ordinarily that discretion will be exercised s...  \n",
       "3  The general principles governing the exercise ...  \n",
       "4  The preceding general principles inform the ex...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "legal_docs = pd.read_csv(\"./data/legal_text_classification.csv\")\n",
    "legal_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cited', 'applied', 'followed', 'referred to', 'related',\n",
       "       'considered', 'discussed', 'distinguished', 'affirmed', 'approved'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (legal_docs.shape)\n",
    "print (legal_docs[\"case_outcome\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Gedeon v Commissioner of New South Wales Crime Commission [2008] HCA 43 ; '\n",
      " '(2008) 82 ALJR 1465 at [43] the High Court said: The expression '\n",
      " '\"jurisdictional fact\" was used somewhat loosely in the course of '\n",
      " 'submissions. Generally the expression is used to identify a criterion the '\n",
      " 'satisfaction of which enlivens the exercise of the statutory power or '\n",
      " 'discretion in question. If the criterion be not satisfied then the decision '\n",
      " 'purportedly made in exercise of the power or discretion will have been made '\n",
      " 'without the necessary statutory authority required of the decision maker.')\n"
     ]
    }
   ],
   "source": [
    "pprint (legal_docs.iloc[100][\"case_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24985 entries, 0 to 24984\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   case_id       24985 non-null  object\n",
      " 1   case_outcome  24985 non-null  object\n",
      " 2   case_title    24985 non-null  object\n",
      " 3   case_text     24809 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 780.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "case_id           0\n",
       "case_outcome      0\n",
       "case_title        0\n",
       "case_text       176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (legal_docs.info())\n",
    "legal_docs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing text with title\n",
    "legal_docs[\"case_text\"] = np.where(legal_docs[\"case_text\"].isna(), legal_docs[\"case_title\"], legal_docs[\"case_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "#module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"\n",
    "\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1024\n",
      "1024 2048\n",
      "2048 3072\n",
      "3072 4096\n",
      "4096 5120\n",
      "5120 6144\n",
      "6144 7168\n",
      "7168 8192\n",
      "8192 9216\n",
      "9216 10240\n",
      "10240 11264\n",
      "11264 12288\n",
      "12288 13312\n",
      "13312 14336\n",
      "14336 15360\n",
      "15360 16384\n",
      "16384 17408\n",
      "17408 18432\n",
      "18432 19456\n",
      "19456 20480\n",
      "20480 21504\n",
      "21504 22528\n",
      "22528 23552\n",
      "23552 24576\n",
      "24576 24985\n",
      "25600 24985\n"
     ]
    }
   ],
   "source": [
    "# without token chunking\n",
    "text_all = legal_docs[\"case_text\"].to_list()\n",
    "docs_chunk_size = 1024\n",
    "current = 0\n",
    "\n",
    "# chunk and create embedded vectors\n",
    "text_embeddings_all = []\n",
    "for i in range(len(text_all)):\n",
    "  # chunk docs\n",
    "  start_i = i*docs_chunk_size\n",
    "  end_i = (i+1)*docs_chunk_size\n",
    "  end_i = end_i if end_i < len(text_all) else len(text_all)\n",
    "\n",
    "  print (start_i, end_i)\n",
    "\n",
    "  docs = text_all[i*docs_chunk_size : (i+1)*docs_chunk_size]\n",
    "  if not docs: break\n",
    "\n",
    "  text_embeddings = embed(docs)\n",
    "  text_embeddings_np = text_embeddings.numpy()\n",
    "  text_embeddings_all.append(text_embeddings_np)\n",
    "\n",
    "  current += docs_chunk_size\n",
    "\n",
    "# handle last chunk before creating reshaping array\n",
    "if len(text_embeddings_all[-1]) != docs_chunk_size:\n",
    "  last_chunk = text_embeddings_all.pop()\n",
    "  last_chunk_np = np.array(last_chunk)\n",
    "  text_embeddings_all_np = np.array(text_embeddings_all)\n",
    "  \n",
    "  n_rows = text_embeddings_all_np.shape[0] * text_embeddings_all_np.shape[1]\n",
    "  text_embeddings_all_np = text_embeddings_all_np.reshape(n_rows, -1)\n",
    "  text_embeddings_all_np = np.r_[text_embeddings_all_np, last_chunk_np]\n",
    "else:\n",
    "  text_embeddings_all_np = np.array(text_embeddings_all)\n",
    "  n_rows = text_embeddings_all_np.shape[0] * text_embeddings_all_np.shape[1]\n",
    "  text_embeddings_all_np = text_embeddings_all_np.reshape(n_rows, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT WORKING - not all docs are chunked evenly (e.g. one doc can have 8 embedded vectors and another can have 1 because they are of different length).\n",
    "# Need to map vector index to doc index somehow. Probably an external index that is used later on during the search when converting the chunk index \n",
    "# to a doc index...\n",
    "\n",
    "# with token chunking\n",
    "\n",
    "# text_all = legal_docs[\"case_text\"].to_list()\n",
    "# docs_chunk_size = 1024\n",
    "# tokens_chunk_size = 512\n",
    "# current = 0\n",
    "\n",
    "# # chunk and create embedded vectors\n",
    "# text_embeddings_all = []\n",
    "# for i in range(len(text_all)):\n",
    "#   # chunk docs\n",
    "#   start_i = i*docs_chunk_size\n",
    "#   end_i = (i+1)*docs_chunk_size\n",
    "#   end_i = end_i if end_i < len(text_all) else len(text_all)\n",
    "\n",
    "#   print (start_i, end_i)\n",
    "\n",
    "#   docs = text_all[i*docs_chunk_size : (i+1)*docs_chunk_size]\n",
    "#   if not docs: break\n",
    "\n",
    "#   # chunk docs tokens\n",
    "#   for doc in docs:\n",
    "#     current_token = 0\n",
    "#     while current_token < len(doc):\n",
    "#       tokens = [doc[current_token : current_token + tokens_chunk_size]]\n",
    "#       text_embeddings = embed(tokens)\n",
    "#       text_embeddings_np = text_embeddings.numpy()\n",
    "#       text_embeddings_all.append(text_embeddings_np)\n",
    "\n",
    "#       current_token += tokens_chunk_size\n",
    "\n",
    "#   current += docs_chunk_size\n",
    "\n",
    "# # handle last chunk before creating reshaping array\n",
    "# if len(text_embeddings_all[-1]) != docs_chunk_size:\n",
    "#   last_chunk = text_embeddings_all.pop()\n",
    "#   last_chunk_np = np.array(last_chunk)\n",
    "#   text_embeddings_all_np = np.array(text_embeddings_all)\n",
    "  \n",
    "#   n_rows = text_embeddings_all_np.shape[0] * text_embeddings_all_np.shape[1]\n",
    "#   text_embeddings_all_np = text_embeddings_all_np.reshape(n_rows, -1)\n",
    "#   text_embeddings_all_np = np.r_[text_embeddings_all_np, last_chunk_np]\n",
    "# else:\n",
    "#   text_embeddings_all_np = np.array(text_embeddings_all)\n",
    "#   n_rows = text_embeddings_all_np.shape[0] * text_embeddings_all_np.shape[1]\n",
    "#   text_embeddings_all_np = text_embeddings_all_np.reshape(n_rows, -1)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24985, 512)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings_all_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(text_embeddings_all_np.shape[1])\n",
    "index.add(text_embeddings_all_np)\n",
    "faiss.write_index(index, \"court_text.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
